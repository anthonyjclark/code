{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_from(lo, hi):\n",
    "    return (hi - lo) * np.random.random() + lo\n",
    "\n",
    "def random_adjust_clipped(value, lo, hi):\n",
    "    new_value = value + np.random.normal(scale=0.1)\n",
    "    return np.clip(new_value, lo, hi)\n",
    "#    return min(max(new_value, lo), hi)\n",
    "\n",
    "def train_nn(lr, beta):\n",
    "    return lr + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.0, 0.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.001, 0.01, 0.1, 1\n",
    "lo = np.log10(0.0001)\n",
    "hi = np.log10(1)\n",
    "lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004358567008523179"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 10**random_from(lo, hi)\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995303919058545"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparamter for exponential smoothing\n",
    "# 0.9 that is going to average the previous 10 values\n",
    "# 0.999 that is going to aver the previous 1000 values\n",
    "# beta is usually chosen from 0.9 to 0.9999\n",
    "# 0.9, 0.99, 0.999, 0.9999\n",
    "# we care less about seeing 0.91 (almost the same as 0.9)\n",
    "# we care less abuot seeing 0.991 (almost the same as 0.99)\n",
    "# 0.9005\n",
    "# Exponential smoothing is more sensitive to values in the upper part of the range\n",
    "# 0.900 --> 0.9005\n",
    "# 0.999 --> 0.9995 (bigger impact on the final result)\n",
    "\n",
    "# 0.9 = 1 - 0.1\n",
    "# 0.99 = 1 - 0.01\n",
    "# 0.999 = 1 - 0.001\n",
    "\n",
    "lo = np.log10(1 - 0.9999)\n",
    "hi = np.log10(1 - 0.9)\n",
    "\n",
    "beta = 1 - 10**random_from(lo, hi)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "Worst method for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 0.1, 0.01, 0.001], [0.9, 0.99, 0.999, 0.9999])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [10**-r for r in range(4)]\n",
    "betas = [1 - 10**-r for r in range(1, 5)]\n",
    "learning_rates, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9 1.9\n",
      "1 0.99 1.99\n",
      "1 0.999 1.999\n",
      "1 0.9999 1.9999\n",
      "0.1 0.9 1.0\n",
      "0.1 0.99 1.09\n",
      "0.1 0.999 1.099\n",
      "0.1 0.9999 1.0999\n",
      "0.01 0.9 0.91\n",
      "0.01 0.99 1.0\n",
      "0.01 0.999 1.009\n",
      "0.01 0.9999 1.0099\n",
      "0.001 0.9 0.901\n",
      "0.001 0.99 0.991\n",
      "0.001 0.999 1.0\n",
      "0.001 0.9999 1.0009\n"
     ]
    }
   ],
   "source": [
    "for lr in learning_rates:\n",
    "    for beta in betas:\n",
    "        loss = train_nn(lr, beta)\n",
    "        print(lr, beta, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9 1.9\n",
      "1 0.99 1.99\n",
      "1 0.999 1.999\n",
      "1 0.9999 1.9999\n",
      "0.1 0.9 1.0\n",
      "0.1 0.99 1.09\n",
      "0.1 0.999 1.099\n",
      "0.1 0.9999 1.0999\n",
      "0.01 0.9 0.91\n",
      "0.01 0.99 1.0\n",
      "0.01 0.999 1.009\n",
      "0.01 0.9999 1.0099\n",
      "0.001 0.9 0.901\n",
      "0.001 0.99 0.991\n",
      "0.001 0.999 1.0\n",
      "0.001 0.9999 1.0009\n"
     ]
    }
   ],
   "source": [
    "# dropout_rates = [0.1 + i/10 for i in range(4)]\n",
    "from itertools import product\n",
    "for lr, beta in product(learning_rates, betas):\n",
    "    loss = train_nn(lr, beta)\n",
    "    print(lr, beta, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03207635774177285 0.9990334026360121 1.031109760377785\n",
      "0.00575246913142425 0.9998541035234998 1.0056065726549241\n",
      "0.015029424642049014 0.9994572271233091 1.0144866517653581\n",
      "0.11152061433860384 0.9909534957303098 1.1024741100689137\n",
      "0.0015276874686569574 0.9789287502846554 0.9804564377533124\n",
      "0.0011280762165611182 0.9991693767023269 1.000297452918888\n",
      "0.009351747444670471 0.9988155652475417 1.0081673126922122\n",
      "0.019671308067394894 0.9963956685217541 1.016066976589149\n",
      "0.7861036901199939 0.9993059496883235 1.7854096398083175\n",
      "0.029511306625670527 0.9981911158684348 1.0277024224941054\n",
      "0.001457400915278945 0.9992205683606564 1.0006779692759353\n",
      "0.0013452125973471706 0.999793431315459 1.001138643912806\n",
      "0.016691075314099735 0.9994996501483603 1.01619072546246\n",
      "0.018035267174211833 0.9914178765300831 1.0094531437042948\n",
      "0.0014662933468557967 0.9995055884589077 1.0009718818057636\n",
      "0.23482932629802658 0.9835173247813805 1.2183466510794072\n"
     ]
    }
   ],
   "source": [
    "lr_lo = np.log10(0.001)\n",
    "lr_hi = np.log10(1)\n",
    "\n",
    "bt_lo = np.log10(1 - .9999)\n",
    "bt_hi = np.log10(1 - .9)\n",
    "\n",
    "num_trials = 16\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    lr = 10**random_from(lr_lo, lr_hi)\n",
    "    beta = 1 - 10**random_from(bt_lo, bt_hi)\n",
    "    loss = train_nn(lr, beta)\n",
    "    print(lr, beta, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Hill Climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climber():\n",
    "    lr_lo = np.log10(0.001)\n",
    "    lr_hi = np.log10(1)\n",
    "    lr_param = random_from(lr_lo, lr_hi)\n",
    "\n",
    "    bt_lo = np.log10(1 - .9999)\n",
    "    bt_hi = np.log10(1 - .9)\n",
    "    bt_param = random_from(bt_lo, bt_hi)\n",
    "\n",
    "    lr = 10**lr_param\n",
    "    beta = 1 - 10**bt_param\n",
    "\n",
    "    best_loss = train_nn(lr, beta)\n",
    "#     print(best_loss)\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "\n",
    "        new_lr_param = random_adjust_clipped(lr_param, lr_lo, lr_hi)\n",
    "        new_bt_param = random_adjust_clipped(bt_param, bt_lo, bt_hi)\n",
    "\n",
    "        new_lr = 10**new_lr_param\n",
    "        new_beta = 1 - 10**new_bt_param\n",
    "\n",
    "        new_loss = train_nn(new_lr, new_beta)\n",
    "\n",
    "        if new_loss < best_loss:\n",
    "            best_loss = new_loss\n",
    "            lr = new_lr\n",
    "            beta = new_beta\n",
    "\n",
    "#         print(best_loss)\n",
    "    \n",
    "    print(\"Best loss was:\", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss was: 0.9440480120457533\n",
      "Best loss was: 1.018834819679194\n",
      "Best loss was: 1.0618571674066508\n",
      "Best loss was: 0.9938809574677866\n",
      "Best loss was: 1.0465753551620418\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    hill_climber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
